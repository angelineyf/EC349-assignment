---
title: "EC349 Individual Assignment"
author: "Angeline Ng"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(dplyr)
library(tidyverse)
library(readr)
```

## Phase 1: Problem Definition
Yelp is a business review platform founded in 2012 to.... This project aims to construct a model that predicts how many stars would a user *i* give to business *j*, based on information about the user and the business. I will utilise all 5 different datasets from Yelp, namely the business, review, user, tip and check-in data. 

Using the work of Shellenberger (2017) as heuristics, the significant business attributes to be included in the predictive model are:
- whether the business accepts credit cards
- the parking options
- whether the business provides catering services
- whether it is good for kids
- whether it offers a brunch menu
- whether it serves alcohol

## Phase 2: Data Understanding and Organisation
A quick glimpse into the datasets suggests that while there exist numerous features which could generate meaningful predictions, many of them are only available in a very small number of entries. Due to this limitation, I will constraint the data to variables that are seemingly widely applicable and easy to be transformed into categorical, boolean or numerical values. 

In order to reduce the computational intensity of data organisation, I will pre-process the datasets individually before merging them into one rectangular data frame. 

```{r load_data, include=FALSE}
#Pre-Processing Yelp Academic Data
library(jsonlite)

#Clear
cat("\014")  
rm(list=ls())

#Set Directory
setwd("C:/Users/angel/OneDrive - University of Warwick/Year 3/EC349 Data Science/R projects/EC349-assignment/Yelp-datasets")

#Load .json Data
business_data <- stream_in(file("yelp_academic_dataset_business.json")) 
checkin_data  <- stream_in(file("yelp_academic_dataset_checkin.json")) 
tip_data  <- stream_in(file("yelp_academic_dataset_tip.json")) 

#Load small data
review_data  <- load(file='yelp_review_small.Rda') 
user_data  <- load(file='yelp_user_small.Rda') 
```

After a quick glimpse of each of the data set, I identified the common column(s) to merge all relevant data into a 2-dimensional data set. I will first merge the business and check in data with common column `business_id`, then merge the review data with all other data by their corresponding `user_id` and `business_id`.

In order to avoid overlapping column names, I renamed the `date` variable in `checkin_data` into `checkin_date`:
```{r}
checkin_data <- checkin_data %>%
  rename(checkin_date = date)
```

Now, the datasets are ready to be merged:
```{r}
#First business and checkin data
merge_business_data <- business_data %>%
  left_join(checkin_data, by = "business_id")

#Then all other data
merged_data <- review_data_small %>%
  left_join(user_data_small, by = "user_id") %>%
  left_join(tip_data, by = c("user_id", "business_id", "date")) %>%
  left_join(merge_business_data, by = "business_id")
```

The `merged_data` should have the same number of observations as the `review_data` (1398056 obs.) and consist of all variables from the 5 datasets.
```{r}
glimpse(merged_data)
```

I noticed that some variables require parsing to better prepare the data for further analysis. 
```{r}
#Transform `date` from <chr> format to <dttr> format
merged_data$date <- parse_datetime(merged_data$date, format = "%Y-%m-%d %H:%M:%S", na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

#Transform `yelping_since` from <chr> format to <dttr> format
merged_data$yelping_since <- parse_datetime(merged_data$yelping_since, format = "%Y-%m-%d %H:%M:%S", na = c("", "NA"), locale = default_locale(), trim_ws = TRUE)

```

The dates of business check-ins is a series of time stamps when a particular business establishment receives a review. could be more useful to be transformed into 

> I'm not too sure if I need to transform the array/list in `elite` and `friends` variables into sub-dataframes or matrices?

I now perform basic correlation analysis/visualisation to identify the relevant variables that could predict users reviews. 

The distribution of stars given by users review:
```{r}
ggplot(merged_data, aes(x = stars.x)) + 
  geom_bar()
```
The distribution of business stars:
```{r}
ggplot(merged_data, aes(x = stars.y)) + 
  geom_histogram()
```




## Phase 3: Validation and Deployment


